{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Test_Annotation.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    text = \" \".join(filtered_tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = text.split()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    text = \" \".join(lemmatized_tokens)\n",
    "    return text\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    data = df.copy()\n",
    "    data[\"clean_comment\"] = data[\"comment\"].apply(preprocess_text)\n",
    "    data.reset_index(inplace=True,drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] =  df['Category'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = '__label__' + df['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df['label'] + ' ' + df['clean_comment']\n",
    "df['label_text'] = df['label_text'].str.rstrip()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=42, stratify = train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"content/train.csv\", columns=[\"label\",\"clean_comment\"], index=False, header=False)\n",
    "valid.to_csv(\"content/dev.csv\", columns=[\"label\",\"clean_comment\"], index=False, header=False)\n",
    "test.to_csv(\"content/test.csv\", columns=[\"label\",\"clean_comment\"], index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dictionary / corpus for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = [(str(row['clean_comment']), str(row['label'])) for index, row in train.iterrows()]\n",
    "data_test = [(str(row['clean_comment']), str(row['label'])) for index, row in test.iterrows()]\n",
    "data_valid = [(str(row['clean_comment']), str(row['label'])) for index, row in valid.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_map = {0: 'text', 1: 'label'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_corpus_dir = 'flair_corpus'\n",
    "os.makedirs(flair_corpus_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.samplers import ImbalancedClassificationDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_csv_file = os.path.join(flair_corpus_dir, 'train.csv')\n",
    "with open(flair_csv_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('text,label\\n')\n",
    "    for row in data_train:\n",
    "        f.write(f'{row[0]},{row[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_csv_file = os.path.join(flair_corpus_dir, 'test.csv')\n",
    "with open(flair_csv_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('text,label\\n')\n",
    "    for row in data_test:\n",
    "        f.write(f'{row[0]},{row[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_csv_file = os.path.join(flair_corpus_dir, 'valid.csv')\n",
    "with open(flair_csv_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('text,label\\n')\n",
    "    for row in data_valid:\n",
    "        f.write(f'{row[0]},{row[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'label'\n",
    "# load corpus containing training, test and dev data\n",
    "corpus = CSVClassificationCorpus(flair_corpus_dir, column_name_map, label_type=label_type)\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "# Create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('content/flair/', \n",
    "              embeddings_storage_mode='gpu',\n",
    "              learning_rate = 0.005,\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4,\n",
    "              sampler=ImbalancedClassificationDatasetSampler,\n",
    "              # train_with_dev= \"True\",\n",
    "              max_epochs=10, \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence \n",
    "from flair.models import TextClassifier \n",
    "c = TextClassifier.load('content/flair/final-model.pt') \n",
    "\n",
    "# input example sentence \n",
    "s = Sentence('i hate your vlogs') \n",
    "\n",
    "# predict class and print \n",
    "c.predict(s) \n",
    "\n",
    "# print the labels \n",
    "print(s.labels) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
